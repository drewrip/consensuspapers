\documentclass{article}
\begin{document}

\tableofcontents{}

\section{Verification and Checking}

\begin{itemize}
	%% Verdi
	\item
	\textit{Verdi: A Framework for Implementing and Formally Verifying Distributed Systems} \cite{Verdi}

	Verdi is a framework for practically verifying distributed systems. Often implementations of distributed systems are
	too complex to be exhaustively tested, so, Verdi attempts to choose an appropriate fault model to more effectively enumerate bugs and faults.
	A toolchain is provided to assist in transforming the formal model of the system into implemenation.

	%% Teaching Rigorous DS W/ Efficient Model Checking
	\item
	\textit{Teaching Rigorous Distributed Systems with Efficient Model Checking} \cite{MichaelWAET2019}

	While exhaustively determining bugs in a distributed system can be incredibly effective, it can, at the same time, be incredibly costly for developers.
	This paper purposes a model that allows students, or developers with fewer resources at their disposal to efficiently verify their systems and visually debug them.
	Also included, are methods to reduce the search space for potential faults in the system and to detect errors in realtime.

	%% Howard's Generalized Consensus Solution
	\item
	\textit{A Generalised Solution to Distributed Consensus} \cite{HowardGeneralized}

	This paper attempts to simplify the general consensus problem. It looks at the general consensus problem, and considers how it may be simplified in universal terms with respect to immutable state. They look specifically at the Paxos algorithm as an example. 
	It is synomomous with consensus, though, can be incredibly difficult to understand. This generalized solution to consensus hopes to quelle some of this confusion.
	In analysis, they find that quorum requirements of many algorithms could in fact be weakend.

\end{itemize}

\section{Consensus}

\begin{itemize}

	\subsection{Improvements on Paxos and State Machine Replication}

	%% Fast Paxos
	\item
	\textit{Fast Paxos} \cite{lamport2006fast}

	Fast Paxos is a new variant of Paxos from Leslie Lamport that emphasizes speed of consensus.
	By reducing the quorom size, and implementing a new \textit{fast} round of Paxos, that tests for liveness.

	%% Lamport's Generalized Consensus
	\item
	\textit{Generalized Consensus and Paxos} \cite{lamport2005generalized}

	This is generalized way of respresesnting the consensus problem.
	Lamport boils down the main goals of Paxos algorithm as a set of mathematical generalizations, that can be proven. He also illustrates that main goals for consensus in terms of command-structure sets.

	%% FuzzyLog
	\item
	\textit{The FuzzyLog: A Partially Ordered Shared Log} \cite{FuzzyLog}

	Given the cost of maintaing a total order with a shared log, FuzzLog proposes using a partial order in order to cut down on the associated expense.
	In this partially ordered log there exist DAGs of updates, that are uniquely \textit{colored} based on geographic region.
	Resulting replication is much simpler to achieve, as differently \textit{colored} chains are stored and have to be explicitly updated at each replica.


	\subsection{Geo-replication and WANs}

	%% SDPaxos
	\item
	\textit{SDPaxos: Building Efficient Semi-Decentralized Geo-replicated State Machines} \cite{zhao2018sdpaxos}

	The distributed systems attemping geo-replication have run into multiple notorious problems: mainly load imbalance.
	SDPaxos proposes an alternative algorithm that is based on Paxos, that separates consensus into two distinct phases, replicating the commands to the nodes, and enforcing a consistent order on the nodes.
	This is done in an attempt to curb workload imbalance by maintaining optimal one-trip latency in two steps.

	%% Mencius
	\item
	\textit{Mencius: building efficient replicated state machines for WANs} \cite{Mencius}

	Traditional consensus algorithms, like Paxos, are effective in local contexts, but in WANs, they often suffer the consequence of geographic separation.
	Often when Paxos, or a version of it, is implemented in a WAN there is a definite increase in network latency, decrease in network throughput and much more prevelant problems with load distribution.
	Mencius however, is the proposed algorithm that attempts to lessen problems traditionally associated with WANs and consensus.
	It does this by partitioning sequences (of commits) across multiple nodes in the network, slowly reducing the load on any one specific participant. Mencius adaptively allows nodes with less load to skip their turns and propose changes.

	%% MDCC
	\item
	\textit{MDCC: Multi-Data Center Consistency} \cite{MDCC}

	MDCC is a commit protocol for geographically separated datacenters.
	Given the increased round-trip time for distant datacenters it becomes imperative to reduce any possible unnecessary messages. MDCC maintains strong consistency while most other similar protocols rely on eventual consistency.
	MDCC's one round-trip commit time is acheived by piggybacking commit state on transaction messages
	and by executing Generalized Paxos in parallel on individual records.
	

	%% Flaw in EPaxos
	\item
	\textit{On the correctness of Egalitarian Paxos} \cite{SutraEPaxos}

	Egalitarian Paxos utilizes an execution graph to order commands in the state machines of individual processes.
	Generally this speeds up latency, as in the most favorable, and most common case, only one round trip time is taken to commit the next command.
	Though while the algorithm is fundementally correct, there is an error that can potentially lead to inconsistency between replicas present in both the Go implementation and the TLA\textsuperscript{+} specification. 

	%% EPaxos
	\item
	\textit{There Is More Consensus in Egalitarian Paxos} \cite{EPaxos}

	EPaxos is a variant of the Paxos algorithm that builds off previous improvements brough on by projects like Mencius and Generalized Paxos.
	It looks to improve load balancing across a wide area network, and to improve the network throughput. With EPaxos, a simply majority of replicas need to be non-faulty.
	This is achieved by removing any leader process, which would serve as a bottleneck. Instead participating nodes have choice as to where they submit.
	As a result the network load can be much more evenly distributed. Now no network recovery is needed when a leader process is downed, creating greater availablity.


\end{itemize}

\section{Databases and Implementations}

\begin{itemize}

	%% Spanner
	\item
	\textit{Spanner: Google's Globally-Distributed Database} \cite{Spanner}

	Spanner is a distributed database developed at Google, with the goal of highly available data in different geographic regions.
	The database is also sharded into multiple Paxos replicas in order to better horizontally scale. Data in Spanner is automatically resharded to balance load.
	Using their novel \textit{TrueTime} API, Spanner shows how it can practically guarantee consistency on top of availability with its hyper realistic clock.

	%% Calvin
	\item
	\textit{Calvin: fast distributed transactions for partitioned database systems} \cite{Calvin}

	Calvin serves as a replication layer that sits on top of a distributed database, attempting to efficiently and cost effectively allow for distributed transactions and easy scaling. The main goal of Calvin, is to make it possible to turn a generic unreplicated database into a fully ACID complaint distributed database.
	To do so, it implements multiple layers for sequencing and ordering transactions into a serial order in a global log. This global log is then used to ensure a proper ordering for each individual partion.

\end{itemize}

\bibliographystyle{acm}
\bibliography{refs}

\end{document}